{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 Block Architecture\n",
    "\n",
    "This section aims to recreate the `transformers.models.gpt2.modeling_gpt2.GPT2Block` architecture, ensuring that $\\text{GPT2Block}(H_i) = H_{i+1}$.\n",
    "\n",
    "The GPT-2 Block comprises three key components:\n",
    "1. **Layer Normalization**\n",
    "2. **Attention Block**\n",
    "3. **Multi-Layer Perceptron**\n",
    "\n",
    "We will reconstruct each component and explain how they contribute to the final output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The self-attention mechanism allows a model to weigh the importance of each word in a sentence when making predictions. For the sentence \"The students opened their books,\" self-attention helps the model understand that \"their\" refers to \"students\" and not \"books.\" It does this by computing attention scores between each word and every other word. These scores determine how much focus to place on each word when generating a representation of the sentence, enabling the model to capture relationships and dependencies across the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dennosity/projects/cookbook/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "from itertools import islice\n",
    "\n",
    "query_start, query_end = 0, 64\n",
    "key_start, key_end = 768, 832\n",
    "value_start, value_end = 1536, 1600\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" Returns relative error using PyTorch \"\"\"\n",
    "    # Calculate the absolute difference\n",
    "    abs_diff = torch.abs(x - y)\n",
    "    \n",
    "    # Calculate the sum of absolute values\n",
    "    abs_sum = torch.abs(x) + torch.abs(y)\n",
    "    \n",
    "    # Compute the relative error, ensuring no division by zero\n",
    "    return torch.max(abs_diff / torch.clamp(abs_sum, min=1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dennosity/projects/cookbook/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "config = AutoConfig.from_pretrained(model_id, output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained(model_id, config=config)\n",
    "\n",
    "batch = [\"The students opened their books\", \"The cat chased the mouse\", \"The chef prepared a meal\"]\n",
    "inputs = tokenizer(batch, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "hidden_states = outputs.hidden_states\n",
    "gpt2_blocks = model.h\n",
    "gpt2_block = gpt2_blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2SdpaAttention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, `tokenizer` maps the input text to indices, similar to how a dictionary or hashmap works.\n",
    "If you're curious about how this vocabulary is created, you can learn more about it by checking out SentencePiece [here](https://github.com/google/sentencepiece)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The students opened their books = [464, 2444, 4721, 511, 3835]\n",
      "The cat chased the mouse = [464, 3797, 26172, 262, 10211]\n",
      "The chef prepared a meal = [464, 21221, 5597, 257, 9799]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"{batch[i]} = {inputs.input_ids[i].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "- Position and word embeddings serve as a lookup table for words in the vocabulary.\n",
    "- Embeddings are represented as a 2-dimensional matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **Word Embeddings**:\n",
    "    - Embeddings are represented as a matrix $\\in \\mathbb{R}^{V \\times D}$.\n",
    "    - $V$ is the length of the vocabulary; $D$ is the length/dimension of the embedding.\n",
    "    - Each row in the matrix represents a specific token index.\n",
    "    - Entries in the row provide information about the corresponding token.\n",
    "    \n",
    "$$\n",
    "\\begin{array}{ccccc}\n",
    "\\text{The} & \\text{students} & \\text{opened} & \\text{their} & \\text{books} \\\\\n",
    "\\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow \\\\\n",
    "464 & 2444 & 4721 & 511 & 3835 \\\\\n",
    "\\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow \\\\\n",
    "\n",
    "\\begin{bmatrix}\n",
    "t_{1,1} \\\\\n",
    "t_{1,2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{1,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "t_{2,1} \\\\\n",
    "t_{2,2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{2,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "t_{3,1} \\\\\n",
    "t_{3,2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{3,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "t_{4,1} \\\\\n",
    "t_{4,2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{4,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "t_{5,1} \\\\\n",
    "t_{5,2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{5,D}\n",
    "\\end{bmatrix}^\\top \\\\\n",
    "\\end{array}\n",
    "\n",
    "\\quad\\implies\n",
    "\n",
    "\\begin{array}{c}\n",
    "\\text{\\text{The students opened their books}} \\\\\n",
    "\\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "t_{1,1} & t_{1,2} & \\cdots & t_{1,D} \\\\\n",
    "t_{2,1} & t_{2,2} & \\cdots & t_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "t_{T,1} & t_{T,2} & \\cdots & t_{T,D}\n",
    "\\end{bmatrix}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Position Embeddings**:\n",
    "    - Embeddings are represented as a matrix $\\in \\mathbb{R}^{L \\times D}$.\n",
    "    - $L$ is the maximum context length; $D$ is the length/dimension of the embedding.\n",
    "    - Each row in the matrix corresponds to the positions represented by the output of `range(L)`.\n",
    "    - Entries in the row provide information about the positoin of each token in the sequence.\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccc}\n",
    "0 & 1 & 2 & 3 & 4 \\\\\n",
    "\\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "p_{1,1} \\\\\n",
    "p_{1,2} \\\\\n",
    "\\vdots \\\\\n",
    "p_{1,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "p_{2,1} \\\\\n",
    "p_{2,2} \\\\\n",
    "\\vdots \\\\\n",
    "p_{2,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "p_{3,1} \\\\\n",
    "p_{3,2} \\\\\n",
    "\\vdots \\\\\n",
    "p_{3,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "p_{4,1} \\\\\n",
    "p_{4,2} \\\\\n",
    "\\vdots \\\\\n",
    "p_{4,D}\n",
    "\\end{bmatrix}^\\top &\n",
    "\\begin{bmatrix}\n",
    "p_{5,1} \\\\\n",
    "p_{5,2} \\\\\n",
    "\\vdots \\\\\n",
    "p_{5,D}\n",
    "\\end{bmatrix}^\\top \\\\\n",
    "\\end{array}\n",
    "\\quad\\implies\n",
    "\\begin{array}{c}\n",
    "\\text{[0, 1, 2, 3, 4]} \\\\\n",
    "\\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "p_{1,1} & p_{1,2} & \\cdots & p_{1,D} \\\\\n",
    "p_{2,1} & p_{2,2} & \\cdots & p_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{T,1} & p_{T,2} & \\cdots & p_{T,D}\n",
    "\\end{bmatrix}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embeddings    : Embedding(50257, 768) -> [50256 tokens,   768 dimensional]\n",
      "Position Embeddings: Embedding(1024, 768)  -> [1024 positions, 768 dimensional]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Embeddings    : {model.wte} -> [50256 tokens,   768 dimensional]\")\n",
    "print(f\"Position Embeddings: {model.wpe}  -> [1024 positions, 768 dimensional]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding Error:    0.0\n",
      "Position Embedding Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, num_entries, entry_dimension):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_entries, entry_dimension))\n",
    "\n",
    "    def forward(self, indices):\n",
    "        return self.weight[indices]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_GPT2(cls, source):\n",
    "        num_entries, entry_dimension = source.weight.shape\n",
    "        embeddings = cls(num_entries, entry_dimension)\n",
    "        embeddings.load_state_dict(source.state_dict())\n",
    "        return embeddings\n",
    "\n",
    "token_ids = inputs.input_ids\n",
    "position_ids = torch.arange(5).expand(3, -1)\n",
    "\n",
    "token_embeddings = Embeddings.from_GPT2(model.wte)\n",
    "position_embeddings = Embeddings.from_GPT2(model.wpe)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_token_embeddings = token_embeddings(token_ids)\n",
    "    expected_token_embeddings = model.wte(token_ids)\n",
    "    \n",
    "    predicted_position_embeddings = position_embeddings(position_ids)\n",
    "    expected_position_embeddings = model.wpe(position_ids)\n",
    "   \n",
    "\n",
    "    print(f\"Token Embedding Error:    {rel_error(predicted_token_embeddings, expected_token_embeddings)}\")\n",
    "    print(f\"Position Embedding Error: {rel_error(predicted_position_embeddings, expected_position_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Hidden State\n",
    "    - The first hidden state of GPT-2 is created by adding the token embeddings with the position embeddings.\n",
    "    - It allows the model to effectively process the input while considering both the content and order of the tokens.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\text{Token Embeddings} \\\\\n",
    "\\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "t_{1,1} & t_{1,2} & \\cdots & t_{1,D} \\\\\n",
    "t_{2,1} & t_{2,2} & \\cdots & t_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "t_{T,1} & t_{T,2} & \\cdots & t_{T,D}\n",
    "\\end{bmatrix}\n",
    "\\end{array}\n",
    "+\n",
    "\\begin{array}{c}\n",
    "\\text{Position Embeddings} \\\\\n",
    "\\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "p_{1,1} & p_{1,2} & \\cdots & p_{1,D} \\\\\n",
    "p_{2,1} & p_{2,2} & \\cdots & p_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "p_{T,1} & p_{T,2} & \\cdots & p_{T,D}\n",
    "\\end{bmatrix}\n",
    "\\end{array}\n",
    "=\n",
    "\\begin{array}{c}\n",
    "\\text{Hidden States} \\\\\n",
    "\\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "h_{1,1} & h_{1,2} & \\cdots & h_{1,D} \\\\\n",
    "h_{2,1} & h_{2,2} & \\cdots & h_{2,D} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "h_{T,1} & h_{T,2} & \\cdots & h_{T,D}\n",
    "\\end{bmatrix}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden State Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predicted_hidden_state0 = predicted_token_embeddings + predicted_position_embeddings\n",
    "    expected_hidden_state0 = hidden_states[0]\n",
    "    \n",
    "    print(f\"Hidden State Error: {rel_error(predicted_hidden_state0, expected_hidden_state0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Block\n",
    "- The attention mechanism starts with layer normalization for training stability.\n",
    "- The hidden state is projected into queries (q), keys (k), and values (v).\n",
    "- Attention scores are calculated using queries and keys to determine token importance.\n",
    "- Outputs from the attention mechanism are projected back into the required dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **Layer Normalization**\n",
    "\n",
    "$$\n",
    "\\text{LayerNorm}(x) = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma + \\beta\n",
    "\\quad;\\quad\n",
    "\\mu = \\frac{1}{D} \\sum_{d=1}^{D} x_d\n",
    "\\quad;\\quad\n",
    "\\sigma^2 = \\frac{1}{D} \\sum_{d=1}^{D} (x_d)^2 - \\mu^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mu$ and $\\sigma^2$ is the mean and variance of the input.\n",
    "- $\\epsilon$ is a small constant for numerical stability.\n",
    "- $\\gamma$ and $\\beta$ are learned parameters for scaling and shifting.\n",
    "\n",
    "Notes:\n",
    "- $D$ is the dimension/axis we calculate the mean\n",
    "- We use the raw moment equation for calculating $\\sigma^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Normalization Error: 2.8775712053175084e-05\n"
     ]
    }
   ],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, num_layers, eps=1e-5) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(num_layers))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_layers))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        mean_x2 = torch.square(x).mean(dim=-1, keepdim=True)\n",
    "        var = mean_x2 - torch.square(mean)\n",
    "\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        x_norm = self.weight * x_norm + self.bias\n",
    "\n",
    "        return x_norm\n",
    "    \n",
    "    @classmethod\n",
    "    def from_GPT2(cls, source):\n",
    "        num_layers = source.weight.shape\n",
    "        layer_norm = cls(num_layers)\n",
    "        layer_norm.load_state_dict(source.state_dict())\n",
    "        \n",
    "        return layer_norm\n",
    "\n",
    "layer_norm = LayerNorm.from_GPT2(gpt2_block.ln_1)\n",
    "with torch.no_grad():\n",
    "    expected_layer_norm = gpt2_block.ln_1(expected_hidden_state0)\n",
    "    predicted_layer_norm = layer_norm(expected_hidden_state0)\n",
    "    \n",
    "    print(f\"Layer Normalization Error: {rel_error(predicted_layer_norm, expected_layer_norm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Conv1d**\n",
    "\n",
    "$$\n",
    "\\text{Input Matrix} = \n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    h_{11} & h_{12} & \\cdots & h_{1D}\n",
    "    \\end{bmatrix}_{h_1} \\\\\n",
    "    \\begin{bmatrix}\n",
    "    h_{21} & h_{22} & \\cdots & h_{2D}\n",
    "    \\end{bmatrix}_{h_2} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\begin{bmatrix}\n",
    "    h_{L1} & h_{L2} & \\cdots & h_{LD}\n",
    "    \\end{bmatrix}_{h_L}\n",
    "\\end{bmatrix}_{L \\times D}\n",
    "\\quad\n",
    "\\text{Filter Weight} = \n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    w_{11} \\\\\n",
    "    w_{21} \\\\\n",
    "    \\vdots \\\\\n",
    "    w_{D1}\n",
    "    \\end{bmatrix}_{w_1}\n",
    "    \\begin{bmatrix}\n",
    "    w_{12} \\\\\n",
    "    w_{22} \\\\\n",
    "    \\vdots \\\\\n",
    "    w_{D2}\n",
    "    \\end{bmatrix}_{w_2}\n",
    "    \\cdots \\quad\n",
    "    \\begin{bmatrix}\n",
    "    w_{1E} \\\\\n",
    "    w_{2E} \\\\\n",
    "    \\vdots \\\\\n",
    "    w_{DE}\n",
    "    \\end{bmatrix}_{w_E}\n",
    "\\end{bmatrix}_{D \\times E}\n",
    "\\quad\n",
    "\\text{Filter Bias} =\n",
    "\\begin{bmatrix}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{E}\n",
    "\\end{bmatrix}_{E \\times 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{out}[L_i, E_j] = \\text{bias}[E_j] + \\sum_{d=0}^{D - 1} \\text{weight}[E_j, d] \\ast \\text{input}[L_i, d]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Query: 1.3251878044684418e-05\n",
      "Predicted Key  : 7.21017386240419e-06\n",
      "Predicted Value: 3.2268785616906825e-06\n"
     ]
    }
   ],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(output_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input @ self.weight + self.bias\n",
    "        return output\n",
    "\n",
    "    @classmethod\n",
    "    def from_GPT2(cls, source, start, end):\n",
    "        input_dim = source.weight.shape[0]\n",
    "        output_dim = end - start\n",
    "        conv1d = cls(input_dim, output_dim) \n",
    "        with torch.no_grad():\n",
    "            conv1d.weight.copy_(source.weight[:, start:end])\n",
    "            conv1d.bias.copy_(source.bias[start:end])\n",
    "\n",
    "        return conv1d\n",
    "\n",
    "query_conv1d = Conv1d.from_GPT2(gpt2_block.attn.c_attn, query_start, query_end)\n",
    "key_conv1d = Conv1d.from_GPT2(gpt2_block.attn.c_attn, key_start, key_end)\n",
    "value_conv1d = Conv1d.from_GPT2(gpt2_block.attn.c_attn, value_start, value_end)   \n",
    "\n",
    "with torch.no_grad():\n",
    "    expected_conv1d = gpt2_block.attn.c_attn(predicted_layer_norm)\n",
    "\n",
    "    expected_query = expected_conv1d[:, :, query_start: query_end]\n",
    "    expected_key = expected_conv1d[:, :, key_start: key_end]\n",
    "    expected_value = expected_conv1d[:, :, value_start: value_end]\n",
    "\n",
    "    predicted_query = query_conv1d(predicted_layer_norm)\n",
    "    predicted_key = key_conv1d(predicted_layer_norm)\n",
    "    predicted_value = value_conv1d(predicted_layer_norm)\n",
    "\n",
    "    print(f\"Predicted Query: {rel_error(predicted_query, expected_query)}\")\n",
    "    print(f\"Predicted Key  : {rel_error(predicted_key, expected_key)}\")\n",
    "    print(f\"Predicted Value: {rel_error(predicted_value, expected_value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV Error        : 8.590293145971373e-05\n",
      "Batch Query Error: 5.80195446673315e-05\n",
      "Batch Key Error  : 8.590293145971373e-05\n",
      "Batch Value Error: 3.689480581670068e-05\n"
     ]
    }
   ],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(output_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input @ self.weight + self.bias\n",
    "        return output\n",
    "    \n",
    "    def split_qkv(self, input, num_heads, head_dim):\n",
    "        query, key, value = input.split(num_heads * head_dim, dim=2)\n",
    "        return query, key, value\n",
    "\n",
    "    @classmethod\n",
    "    def from_GPT2(cls, source):\n",
    "        input_dim, output_dim = source.weight.shape\n",
    "        conv1d = cls(input_dim, output_dim)\n",
    "        conv1d.load_state_dict(source.state_dict())\n",
    "\n",
    "        return conv1d\n",
    "\n",
    "conv1d = Conv1d.from_GPT2(gpt2_block.attn.c_attn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    expected_qkv = gpt2_block.attn.c_attn(predicted_layer_norm)\n",
    "    expected_query, expected_key, expected_value = expected_qkv.split(768, dim=2)\n",
    "\n",
    "    predicted_qkv = conv1d(predicted_layer_norm)\n",
    "    predicted_query, predicted_key, predicted_value = predicted_qkv.split(768, dim=2)\n",
    "\n",
    "    print(f\"QKV Error        : {rel_error(predicted_qkv, expected_qkv)}\")\n",
    "\n",
    "    print(f\"Batch Query Error: {rel_error(predicted_query, expected_query)}\")\n",
    "    print(f\"Batch Key Error  : {rel_error(predicted_key, expected_key)}\")\n",
    "    print(f\"Batch Value Error: {rel_error(predicted_value, expected_value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Attention Mechanism**\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\underbrace{\\text{softmax} \\left( \\frac{Q K^T}{\\sqrt{\\text{dim}_k}} \\right)}_{\\text{Attention Score}} \\underbrace{\\phantom{\\frac{V}{V}} V \\phantom{\\frac{V}{V}}}_{\\text{Hidden State}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ 3.1. **Attention Score**:\n",
    "\n",
    "The sentence tokens are represented as embeddings in the query (Q) and key (K) matrices. Each token, such as \"books,\" \"The,\" \"students,\" etc., is associated with query and key vectors:\n",
    "\n",
    "$$\n",
    "\\text{softmax}\\left(\n",
    "\\begin{array}{cccccc}\n",
    "\\text{books/} q_0 & & \\text{The/} k_0 & \\text{students/} k_1 & \\text{opened/} k_2 & \\text{their/} k_3 & \\text{books/} k_4 \\\\\n",
    "\\downarrow & & \\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow \\\\\n",
    "\\begin{bmatrix}\n",
    "q_0 & q_1 & \\cdots & q_{E-1}\n",
    "\\end{bmatrix} &\n",
    "\\cdot &\n",
    "\\begin{bmatrix}\n",
    "k_{0,0} \\\\\n",
    "k_{1,0} \\\\\n",
    "\\vdots \\\\\n",
    "k_{E-1,0}\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "k_{0,1} \\\\\n",
    "k_{1,1} \\\\\n",
    "\\vdots \\\\\n",
    "k_{E-1,1}\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "k_{0,2} \\\\\n",
    "k_{1,2} \\\\\n",
    "\\vdots \\\\\n",
    "k_{E-1,2}\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "k_{0,3} \\\\\n",
    "k_{1,3} \\\\\n",
    "\\vdots \\\\\n",
    "k_{E-1,3}\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "k_{0,4} \\\\\n",
    "k_{1,4} \\\\\n",
    "\\vdots \\\\\n",
    "k_{E-1,4}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\n",
    "\\begin{array}{cccccc}\n",
    "\\text{The} & \\text{students} & \\text{opened} & \\text{their} & \\text{books} \\\\\n",
    "\\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow \\\\\n",
    "0.051 & 0.511 & 0.069 & 0.057 & 0.310\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- The dot product $QK^T$ computes how similar each query is to the keys.\n",
    "- $\\sqrt{\\text{dim}_k}$ ensures numeric stability\n",
    "- Applying the softmax function ensures that the **attention scores for each query sum** to 1, producing a weighted distribution over all the values (V)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ 3.2. **Attention Outputs**:\n",
    "\n",
    "Each value vector $v$ is multiplied by its corresponding attention weight. These weighted values are then combined to form the final output of the attention mechanism, which is a weighted sum of the value vectors.\n",
    "$$\n",
    "\\begin{array}{cccccc}\n",
    "    & \\text{The} & \\text{students} & \\text{opened} & \\text{their} & \\text{books} \\\\\n",
    "    & \\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow \\\\\n",
    "\\text{book} \\rightarrow & [\\quad 0.051 \\cdot v_0 & 0.511 \\cdot v_1 & 0.069 \\cdot v_2 & 0.057 \\cdot v_3 & 0.310 \\cdot v_4\\quad]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- The right-hand part, $V$ hold the actual information the attention mechanism will pass forward.\n",
    "- The attention scores act as weights applied to the value vectors, determining how much attention each query should give to each corresponding value vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "def attention_score(query, key, values):\n",
    "    key_dim = key.shape[-1]\n",
    "    attn_weights = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(key_dim)\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "\n",
    "    attn_output = torch.matmul(attn_weights, values)\n",
    "    return attn_output\n",
    "\n",
    "with torch.no_grad():\n",
    "    expected_attn_output = F.scaled_dot_product_attention(expected_query, expected_key, expected_value, is_causal=False)\n",
    "    predicted_attn_output = attention_score(expected_query, expected_key, expected_value)\n",
    "\n",
    "    print(rel_error(expected_attn_output, predicted_attn_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ 3.3. **Causal Mask**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "def attention_score(query, key, values, is_causal=True):\n",
    "    query_length = query.shape[-2]\n",
    "    key_length, key_dim = key.shape[-2], key.shape[-1]\n",
    "    \n",
    "    attn_weights = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(key_dim)\n",
    "    \n",
    "    if is_causal:\n",
    "        causal_mask = torch.ones(query_length, key_length, dtype=torch.bool).tril(diagonal=0)\n",
    "        attn_weights = torch.where(causal_mask, attn_weights, float(\"-inf\"))\n",
    "\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "    attn_output = torch.matmul(attn_weights, values)\n",
    "    return attn_output\n",
    "\n",
    "with torch.no_grad():\n",
    "    expected_attn_output = gpt2_block.attn._attn(expected_query, expected_key, expected_value)[0]\n",
    "    predicted_attn_output = attention_score(expected_query, expected_key, expected_value)\n",
    "\n",
    "    print(rel_error(expected_attn_output, predicted_attn_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ 3.4. **Batched Multi-Attention**:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
